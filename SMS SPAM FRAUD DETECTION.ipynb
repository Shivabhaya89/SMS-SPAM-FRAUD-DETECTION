{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14e18d4e-3504-410b-963e-43f7e5f4671c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "DATA COPIED SUCESSFULLY  \n",
      "     v1                                                 v2 Unnamed: 2  \\\n",
      "0  ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
      "1  ham                      Ok lar... Joking wif u oni...        NaN   \n",
      "\n",
      "  Unnamed: 3 Unnamed: 4  \n",
      "0        NaN        NaN  \n",
      "1        NaN        NaN  \n",
      "\n",
      "\n",
      "RENAMED SUCESSFULLY  \n",
      "   Label                                               Text\n",
      "0   ham  Go until jurong point, crazy.. Available only ...\n",
      "1   ham                      Ok lar... Joking wif u oni...\n",
      "\n",
      "\n",
      "PLOTING BAR GRAPH ON COUNT v/s LABEL \n",
      " \n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AVERAGE WORD LENGTH IS:-  15 \n",
      "\n",
      "TOTAL WORD LENGTH IS:- 15585 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers \n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout, BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "# Load and preprocess the dataset\n",
    "raw_data = pd.read_csv('C:/Users/Lenovo/Desktop/DATA ANALYSIS Practice/spam.csv', encoding='latin-1')\n",
    "raw_data.head()\n",
    "\n",
    "#Creating copy of original data\n",
    "data=raw_data.copy()\n",
    "print(\"DATA COPIED SUCESSFULLY  \\n\",data.head(2))\n",
    "\n",
    "# Selecting only the columns with SMS text and labels\n",
    "data = data[['v1', 'v2']]  \n",
    "\n",
    "# Renaming the columns for clarity\n",
    "data.columns = ['Label', 'Text']  \n",
    "print(\"\\n\\nRENAMED SUCESSFULLY  \\n\",data.head(2))\n",
    "\n",
    "# Encoding labels\n",
    "data['Label'] = data['Label'].map({'ham': 0, 'spam': 1})\n",
    "\n",
    "#DISPLAY PLOT\n",
    "print(\"\\n\\nPLOTING BAR GRAPH ON COUNT v/s LABEL \\n \\n\")\n",
    "sns.countplot(x=data['Label'])\n",
    "plt.show()\n",
    "\n",
    "avg_word_length=round(sum([len(i.split()) for i in data['Text']])/len(data['Text']))\n",
    "print(\"\\nAVERAGE WORD LENGTH IS:- \",avg_word_length,\"\\n\")\n",
    "\n",
    "s=set()\n",
    "for sent in data['Text']:\n",
    "    for word in sent.split():\n",
    "        s.add(word)\n",
    "total_word_length=len(s)\n",
    "print(\"TOTAL WORD LENGTH IS:-\",total_word_length,\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3d1f72c-3216-4add-84ea-868743ddecbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9623318385650225\n",
      "\n",
      "\n",
      "CLASSIFICATION REPORT: \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98       965\n",
      "           1       1.00      0.72      0.84       150\n",
      "\n",
      "    accuracy                           0.96      1115\n",
      "   macro avg       0.98      0.86      0.91      1115\n",
      "weighted avg       0.96      0.96      0.96      1115\n",
      "\n",
      "\n",
      "\n",
      "THIS IS MODEL SUMMERY\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:86: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ text_vectorization                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TextVectorization</span>)                  │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)             │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,994,880</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ global_average_pooling1d             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)             │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">4,128</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ text_vectorization                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mTextVectorization\u001b[0m)                  │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m128\u001b[0m)             │       \u001b[38;5;34m1,994,880\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ global_average_pooling1d             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)             │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │           \u001b[38;5;34m4,128\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m33\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,999,041</span> (7.63 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,999,041\u001b[0m (7.63 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,999,041</span> (7.63 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,999,041\u001b[0m (7.63 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X,y=np.asanyarray(data['Text']), np.asanyarray(data['Label'])\n",
    "data=pd.DataFrame({'Text':X,'Label':y})\n",
    "X_train,X_test,y_train,y_test = train_test_split(data['Text'],data['Label'],test_size=0.2,random_state=42)\n",
    "X_train.shape,y_train.shape,X_test.shape,y_test.shape\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report,accuracy_score\n",
    " \n",
    "tfidf_vec = TfidfVectorizer().fit(X_train)\n",
    "X_train_vec,X_test_vec = tfidf_vec.transform(X_train),tfidf_vec.transform(X_test)\n",
    " \n",
    "base_model = MultinomialNB()\n",
    "base_model.fit(X_train_vec,y_train)\n",
    "\n",
    "nb_accuracy=accuracy_score(y_test,base_model.predict(X_test_vec))\n",
    "print(nb_accuracy)\n",
    "print(\"\\n\\nCLASSIFICATION REPORT: \\n\\n\",classification_report(y_test,base_model.predict(X_test_vec)))\n",
    "\n",
    "from tensorflow.keras.layers import TextVectorization\n",
    "\n",
    "MAXTOKENS=total_word_length\n",
    "OUTPUTLEN=avg_word_length\n",
    "print(\"\\n\\nTHIS IS MODEL SUMMERY\\n\")\n",
    "text_vec = TextVectorization(\n",
    "    max_tokens=MAXTOKENS,\n",
    "    standardize='lower_and_strip_punctuation',\n",
    "    output_mode='int',\n",
    "    output_sequence_length=OUTPUTLEN\n",
    ")\n",
    "text_vec.adapt(X_train)\n",
    "sample_sentence = \"this is a message\"\n",
    "text_vec([sample_sentence])\n",
    "\n",
    "embedding_layer = layers.Embedding(\n",
    "    input_dim=MAXTOKENS,\n",
    "    output_dim=128,\n",
    "    embeddings_initializer='uniform',\n",
    "    input_length=OUTPUTLEN\n",
    ")\n",
    "\n",
    "input_layer = layers.Input(shape=(1,), dtype=tf.string)\n",
    "vec_layer = text_vec(input_layer)\n",
    "embedding_layer_model = embedding_layer(vec_layer)\n",
    "x = layers.GlobalAveragePooling1D()(embedding_layer_model)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(32, activation='relu')(x)\n",
    "output_layer = layers.Dense(1, activation='sigmoid')(x)\n",
    "model_1 = keras.Model(input_layer, output_layer)\n",
    " \n",
    "model_1.compile(optimizer='adam', loss=keras.losses.BinaryCrossentropy(\n",
    "    label_smoothing=0.5), metrics=['accuracy'])\n",
    "model_1.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ac30e09-f2ec-44b3-9344-c9190218a200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 95ms/step - accuracy: 0.8888 - loss: 0.3230 - val_accuracy: 0.9740 - val_loss: 0.0845\n",
      "Epoch 2/5\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 90ms/step - accuracy: 0.9865 - loss: 0.0521 - val_accuracy: 0.9794 - val_loss: 0.0675\n",
      "Epoch 3/5\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 91ms/step - accuracy: 0.9950 - loss: 0.0299 - val_accuracy: 0.9803 - val_loss: 0.0708\n",
      "Epoch 4/5\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 94ms/step - accuracy: 0.9985 - loss: 0.0115 - val_accuracy: 0.9794 - val_loss: 0.0736\n",
      "Epoch 5/5\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 87ms/step - accuracy: 0.9976 - loss: 0.0132 - val_accuracy: 0.9767 - val_loss: 0.0795\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.9799 - loss: 0.0703\n",
      "Test Accuracy: 0.9766815900802612\n"
     ]
    }
   ],
   "source": [
    "#  Splitting the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data['Text'], data['Label'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Tokenization and Padding\n",
    "max_words = 1000\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "X_train_sequences = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_sequences = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "max_sequence_length = 100\n",
    "X_train_pad = pad_sequences(X_train_sequences, maxlen=max_sequence_length)\n",
    "X_test_pad = pad_sequences(X_test_sequences, maxlen=max_sequence_length)\n",
    "\n",
    "# Building the model\n",
    "embedding_dim = 100\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=max_words, output_dim=embedding_dim, input_length=max_sequence_length),\n",
    "    LSTM(units=64),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "# Training the model\n",
    "history = model.fit(X_train_pad, y_train, epochs=5, batch_size=32, validation_data=(X_test_pad, y_test))\n",
    "\n",
    "# Evaluating the model\n",
    "loss, accuracy = model.evaluate(X_test_pad, y_test)\n",
    "print(\"Test Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0681ffd3-df78-4038-860e-aa4e89e15c46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:86: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 122ms/step - accuracy: 0.9004 - loss: 0.3121 - val_accuracy: 0.9785 - val_loss: 0.0742\n",
      "Epoch 2/5\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 135ms/step - accuracy: 0.9887 - loss: 0.0447 - val_accuracy: 0.9803 - val_loss: 0.0641\n",
      "Epoch 3/5\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 151ms/step - accuracy: 0.9940 - loss: 0.0227 - val_accuracy: 0.9776 - val_loss: 0.0627\n",
      "Epoch 4/5\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 262ms/step - accuracy: 0.9976 - loss: 0.0130 - val_accuracy: 0.9758 - val_loss: 0.0725\n",
      "Epoch 5/5\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 145ms/step - accuracy: 0.9968 - loss: 0.0105 - val_accuracy: 0.9785 - val_loss: 0.0762\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 149ms/step - accuracy: 0.8905 - loss: 0.3338 - val_accuracy: 0.9758 - val_loss: 0.0796\n",
      "Epoch 1/5\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 165ms/step - accuracy: 0.8972 - loss: 0.3008 - val_accuracy: 0.9803 - val_loss: 0.0770\n",
      "Epoch 2/5\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 166ms/step - accuracy: 0.9875 - loss: 0.0484 - val_accuracy: 0.9803 - val_loss: 0.0631\n",
      "Epoch 3/5\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 162ms/step - accuracy: 0.9929 - loss: 0.0258 - val_accuracy: 0.9803 - val_loss: 0.0719\n",
      "Epoch 4/5\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 100ms/step - accuracy: 0.9973 - loss: 0.0108 - val_accuracy: 0.9767 - val_loss: 0.0747\n",
      "Epoch 5/5\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 104ms/step - accuracy: 0.9977 - loss: 0.0074 - val_accuracy: 0.9749 - val_loss: 0.0972\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9846 - loss: 0.0692\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.9779 - loss: 0.0668\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9765 - loss: 0.0884\n",
      "                             Accuracy\n",
      "MultinomialNB Model          0.789238\n",
      "Custom-Vec-Embedding Model   0.978475\n",
      "Bidirectional-LSTM Model     0.975785\n",
      "USE-Transfer learning Model  0.974888\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Define the evaluate_model function for TensorFlow/Keras models\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    # Evaluate the model\n",
    "    loss, accuracy = model.evaluate(X_test, y_test)\n",
    "    return {'Loss': loss, 'Accuracy': accuracy}\n",
    "\n",
    "# Define the evaluate_model function for scikit-learn models\n",
    "def evaluate_model_sklearn(model, X_test, y_test):\n",
    "    # Predict on the test data\n",
    "    y_pred = model.predict(X_test)\n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    return {'Accuracy': accuracy}\n",
    "    \n",
    "# Building and training the Multinomial Naive Bayes model\n",
    "baseline_model = MultinomialNB()\n",
    "baseline_model.fit(X_train_pad, y_train)\n",
    "\n",
    "# Building and training other models \n",
    "model_1 = Sequential([\n",
    "    Embedding(input_dim=max_words, output_dim=100, input_length=max_sequence_length),\n",
    "    LSTM(units=64),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "model_1.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model_1.fit(X_train_pad, y_train, epochs=5, batch_size=32, validation_data=(X_test_pad, y_test))\n",
    "\n",
    "model_2 = Sequential([\n",
    "    Embedding(input_dim=max_words, output_dim=100, input_length=max_sequence_length),\n",
    "    LSTM(units=64),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "model_2.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model_2.fit(X_train_pad, y_train, epochs=1, batch_size=32, validation_data=(X_test_pad, y_test))\n",
    "\n",
    "model_3 = Sequential([\n",
    "    Embedding(input_dim=max_words, output_dim=100, input_length=max_sequence_length),\n",
    "    LSTM(units=64),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "model_3.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model_3.fit(X_train_pad, y_train, epochs=5, batch_size=32, validation_data=(X_test_pad, y_test))\n",
    "\n",
    "# Evaluate other models \n",
    "baseline_model_results = {'Accuracy': baseline_model.score(X_test_pad, y_test)}\n",
    "model_1_results = {'Accuracy': model_1.evaluate(X_test_pad, y_test)[1]}\n",
    "model_2_results = {'Accuracy': model_2.evaluate(X_test_pad, y_test)[1]}\n",
    "model_3_results = {'Accuracy': model_3.evaluate(X_test_pad, y_test)[1]}\n",
    "                  \n",
    "\n",
    "total_results = pd.DataFrame({'MultinomialNB Model':baseline_model_results,\n",
    "                             'Custom-Vec-Embedding Model':model_1_results,\n",
    "                             'Bidirectional-LSTM Model':model_2_results,\n",
    "                             'USE-Transfer learning Model':model_3_results}).transpose()\n",
    "\n",
    "\n",
    "print(total_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b64da25-1501-45b1-82cb-852fe821392e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
